{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (c) 2014 Reid Johnson\n",
      "#\n",
      "# Functions to work with continuous data and linear regression models.\n",
      "\n",
      "import matplotlib.pyplot as pl\n",
      "\n",
      "def pairs(data):\n",
      "    \"\"\"Generates and shows a pairwise scatterplot of the dataset features.\n",
      "\n",
      "    A figure with nxn scatterplots is generated, where n is the number of features. The features are\n",
      "    defined as the all columns excluding the final column, which is defined as the class.\n",
      "\n",
      "    Args:\n",
      "      data (array): A dataset.\n",
      "\n",
      "    \"\"\"\n",
      "    i = 1\n",
      "\n",
      "    # Divide columns into features and class\n",
      "    features = list(data.columns)\n",
      "    classes = features[-1] # create class column\n",
      "    del features[-1] # delete class column from feature vector\n",
      "\n",
      "    # Generate an nxn subplot figure, where n is the number of features\n",
      "    figure = pl.figure(figsize=(5*(len(data.columns)-1), 4*(len(data.columns)-1)))\n",
      "    for col1 in data[features]:\n",
      "        for col2 in data[features]:\n",
      "            ax = pl.subplot(len(data.columns)-1, len(data.columns)-1, i)\n",
      "            if col1 == col2:\n",
      "                ax.text(2.5, 4.5, col1, style='normal', fontsize=20)\n",
      "                ax.axis([0, 10, 0, 10])\n",
      "                pl.xticks([]), pl.yticks([])\n",
      "            else:\n",
      "                for name in data[classes]:\n",
      "                    cond = data[classes] == name\n",
      "                    ax.plot(data[col2][cond], data[col1][cond], linestyle='none', marker='o', label=name)\n",
      "                #t = plt.title(name)\n",
      "            i += 1\n",
      "\n",
      "    pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# HOG feature from scikit-image; does not implement the visualization capability.\n",
      "#\n",
      "# https://github.com/scikit-image/scikit-image/blob/master/skimage/feature/_hog.py\n",
      "\n",
      "import numpy as np\n",
      "from scipy import sqrt, pi, arctan2, cos, sin\n",
      "from scipy.ndimage import uniform_filter\n",
      "\n",
      "\n",
      "def hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
      "        cells_per_block=(3, 3), visualise=False, normalise=False):\n",
      "    \"\"\"Extract Histogram of Oriented Gradients (HOG) for a given image.\n",
      "\n",
      "    Compute a Histogram of Oriented Gradients (HOG) by\n",
      "\n",
      "        1. (optional) global image normalisation\n",
      "        2. computing the gradient image in x and y\n",
      "        3. computing gradient histograms\n",
      "        4. normalising across blocks\n",
      "        5. flattening into a feature vector\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    image : (M, N) ndarray\n",
      "        Input image (greyscale).\n",
      "    orientations : int\n",
      "        Number of orientation bins.\n",
      "    pixels_per_cell : 2 tuple (int, int)\n",
      "        Size (in pixels) of a cell.\n",
      "    cells_per_block  : 2 tuple (int,int)\n",
      "        Number of cells in each block.\n",
      "    visualise : bool, optional\n",
      "        Also return an image of the HOG.\n",
      "    normalise : bool, optional\n",
      "        Apply power law compression to normalise the image before\n",
      "        processing.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    newarr : ndarray\n",
      "        HOG for the image as a 1D (flattened) array.\n",
      "    hog_image : ndarray (if visualise=True)\n",
      "        A visualisation of the HOG image.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    * http://en.wikipedia.org/wiki/Histogram_of_oriented_gradients\n",
      "\n",
      "    * Dalal, N and Triggs, B, Histograms of Oriented Gradients for\n",
      "      Human Detection, IEEE Computer Society Conference on Computer\n",
      "      Vision and Pattern Recognition 2005 San Diego, CA, USA\n",
      "\n",
      "    \"\"\"\n",
      "    image = np.atleast_2d(image)\n",
      "\n",
      "    \"\"\"\n",
      "    The first stage applies an optional global image normalisation\n",
      "    equalisation that is designed to reduce the influence of illumination\n",
      "    effects. In practice we use gamma (power law) compression, either\n",
      "    computing the square root or the log of each colour channel.\n",
      "    Image texture strength is typically proportional to the local surface\n",
      "    illumination so this compression helps to reduce the effects of local\n",
      "    shadowing and illumination variations.\n",
      "    \"\"\"\n",
      "\n",
      "    if image.ndim > 2:\n",
      "        raise ValueError(\"Currently only supports grey-level images\")\n",
      "\n",
      "    if normalise:\n",
      "        image = sqrt(image)\n",
      "\n",
      "    \"\"\"\n",
      "    The second stage computes first order image gradients. These capture\n",
      "    contour, silhouette and some texture information, while providing\n",
      "    further resistance to illumination variations. The locally dominant\n",
      "    colour channel is used, which provides colour invariance to a large\n",
      "    extent. Variant methods may also include second order image derivatives,\n",
      "    which act as primitive bar detectors - a useful feature for capturing,\n",
      "    e.g. bar like structures in bicycles and limbs in humans.\n",
      "    \"\"\"\n",
      "\n",
      "    if image.dtype.kind == 'u':\n",
      "        # convert uint image to float\n",
      "        # to avoid problems with subtracting unsigned numbers in np.diff()\n",
      "        image = image.astype('float')\n",
      "\n",
      "    gx = np.zeros(image.shape)\n",
      "    gy = np.zeros(image.shape)\n",
      "    gx[:, :-1] = np.diff(image, n=1, axis=1)\n",
      "    gy[:-1, :] = np.diff(image, n=1, axis=0)\n",
      "\n",
      "    \"\"\"\n",
      "    The third stage aims to produce an encoding that is sensitive to\n",
      "    local image content while remaining resistant to small changes in\n",
      "    pose or appearance. The adopted method pools gradient orientation\n",
      "    information locally in the same way as the SIFT [Lowe 2004]\n",
      "    feature. The image window is divided into small spatial regions,\n",
      "    called \"cells\". For each cell we accumulate a local 1-D histogram\n",
      "    of gradient or edge orientations over all the pixels in the\n",
      "    cell. This combined cell-level 1-D histogram forms the basic\n",
      "    \"orientation histogram\" representation. Each orientation histogram\n",
      "    divides the gradient angle range into a fixed number of\n",
      "    predetermined bins. The gradient magnitudes of the pixels in the\n",
      "    cell are used to vote into the orientation histogram.\n",
      "    \"\"\"\n",
      "\n",
      "    magnitude = sqrt(gx**2 + gy**2)\n",
      "    orientation = arctan2(gy, gx) * (180 / pi) % 180\n",
      "\n",
      "    sy, sx = image.shape\n",
      "    cx, cy = pixels_per_cell\n",
      "    bx, by = cells_per_block\n",
      "\n",
      "    n_cellsx = int(np.floor(sx // cx))  # number of cells in x\n",
      "    n_cellsy = int(np.floor(sy // cy))  # number of cells in y\n",
      "\n",
      "    # compute orientations integral images\n",
      "    orientation_histogram = np.zeros((n_cellsy, n_cellsx, orientations))\n",
      "    subsample = np.index_exp[cy / 2:cy * n_cellsy:cy, cx / 2:cx * n_cellsx:cx]\n",
      "    for i in range(orientations):\n",
      "        #create new integral image for this orientation\n",
      "        # isolate orientations in this range\n",
      "\n",
      "        temp_ori = np.where(orientation < 180.0 / orientations * (i + 1),\n",
      "                            orientation, -1)\n",
      "        temp_ori = np.where(orientation >= 180.0 / orientations * i,\n",
      "                            temp_ori, -1)\n",
      "        # select magnitudes for those orientations\n",
      "        cond2 = temp_ori > -1\n",
      "        temp_mag = np.where(cond2, magnitude, 0)\n",
      "\n",
      "        temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
      "        orientation_histogram[:, :, i] = temp_filt[subsample]\n",
      "\n",
      "    # now for each cell, compute the histogram\n",
      "    hog_image = None\n",
      "\n",
      "    #if visualise:\n",
      "    #    from skimage import draw\n",
      "\n",
      "    #    radius = min(cx, cy) // 2 - 1\n",
      "    #    hog_image = np.zeros((sy, sx), dtype=float)\n",
      "    #    for x in range(n_cellsx):\n",
      "    #        for y in range(n_cellsy):\n",
      "    #            for o in range(orientations):\n",
      "    #                centre = tuple([y * cy + cy // 2, x * cx + cx // 2])\n",
      "    #                dx = radius * cos(float(o) / orientations * np.pi)\n",
      "    #                dy = radius * sin(float(o) / orientations * np.pi)\n",
      "    #                rr, cc = draw.line(int(centre[0] - dx),\n",
      "    #                                   int(centre[1] - dy),\n",
      "    #                                   int(centre[0] + dx),\n",
      "    #                                   int(centre[1] + dy))\n",
      "    #                hog_image[rr, cc] += orientation_histogram[y, x, o]\n",
      "\n",
      "    \"\"\"\n",
      "    The fourth stage computes normalisation, which takes local groups of\n",
      "    cells and contrast normalises their overall responses before passing\n",
      "    to next stage. Normalisation introduces better invariance to illumination,\n",
      "    shadowing, and edge contrast. It is performed by accumulating a measure\n",
      "    of local histogram \"energy\" over local groups of cells that we call\n",
      "    \"blocks\". The result is used to normalise each cell in the block.\n",
      "    Typically each individual cell is shared between several blocks, but\n",
      "    its normalisations are block dependent and thus different. The cell\n",
      "    thus appears several times in the final output vector with different\n",
      "    normalisations. This may seem redundant but it improves the performance.\n",
      "    We refer to the normalised block descriptors as Histogram of Oriented\n",
      "    Gradient (HOG) descriptors.\n",
      "    \"\"\"\n",
      "\n",
      "    n_blocksx = (n_cellsx - bx) + 1\n",
      "    n_blocksy = (n_cellsy - by) + 1\n",
      "    normalised_blocks = np.zeros((n_blocksy, n_blocksx,\n",
      "                                  by, bx, orientations))\n",
      "\n",
      "    for x in range(n_blocksx):\n",
      "        for y in range(n_blocksy):\n",
      "            block = orientation_histogram[y:y + by, x:x + bx, :]\n",
      "            eps = 1e-5\n",
      "            normalised_blocks[y, x, :] = block / sqrt(block.sum()**2 + eps)\n",
      "\n",
      "    \"\"\"\n",
      "    The final step collects the HOG descriptors from all blocks of a dense\n",
      "    overlapping grid of blocks covering the detection window into a combined\n",
      "    feature vector for use in the window classifier.\n",
      "    \"\"\"\n",
      "\n",
      "    if visualise:\n",
      "        return normalised_blocks.ravel(), hog_image\n",
      "    else:\n",
      "        return normalised_blocks.ravel()\n",
      "\n",
      "\n",
      "# Convert color image to grayscale.\n",
      "import numpy as np\n",
      "\n",
      "def rgb2gray(rgb):\n",
      "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (c) 2014 Reid Johnson\n",
      "#\n",
      "# Function to download images from Google Image search.\n",
      "\n",
      "import Image\n",
      "import json\n",
      "import os\n",
      "from StringIO import StringIO\n",
      "import time\n",
      "import urllib\n",
      "import urllib2\n",
      "\n",
      "#from bs4 import BeautifulSoup\n",
      "try:\n",
      "    import simplejson as json\n",
      "except:\n",
      "    import json\n",
      "#from skimage import color, exposure\n",
      "#from skimage.feature import hog\n",
      "\n",
      "def go_google_image(query, path, max_num=60):\n",
      "    \"\"\"Download full-size images from Google image search.\n",
      "\n",
      "    Don't print or republish images without permission.\n",
      "    \"\"\"\n",
      "    BASE_URL = 'https://ajax.googleapis.com/ajax/services/search/images?'\\\n",
      "               'v=1.0&q=' + urllib.quote_plus(query) + '&start=%d'\n",
      "\n",
      "    BASE_PATH = os.path.join(path, query)\n",
      "\n",
      "    if not os.path.exists(BASE_PATH):\n",
      "        os.makedirs(BASE_PATH)\n",
      "\n",
      "    num = 0 # the number of images downloaded\n",
      "    start = 0 # Google's start query string parameter for pagination\n",
      "    while num < max_num and start < 56: # Google will only return a maximum of 60 results\n",
      "        #text = BeautifulSoup(urllib2.urlopen(BASE_URL % start).read()).text\n",
      "        text = urllib.urlopen(BASE_URL % start).read()\n",
      "        if json.loads(text)['responseData'] is None:\n",
      "            continue\n",
      "\n",
      "        for image_info in json.loads(text)['responseData']['results']:\n",
      "            url = image_info['unescapedUrl']\n",
      "\n",
      "            try:\n",
      "                print \"%d -- Downloading %s ...\" % (num+1, url),\n",
      "                image_data = urllib2.urlopen(url).read()\n",
      "                print \"done.\"\n",
      "            except urllib2.HTTPError, e:\n",
      "                print \"downloading FAILED.\"\n",
      "                continue\n",
      "\n",
      "            # Remove file-system path characters from name\n",
      "            title = image_info['titleNoFormatting']\n",
      "            title = title.replace('/', '')\n",
      "            title = title.replace('\\\\', '')\n",
      "            title = title.replace(':', '')\n",
      "            title = title.replace('|', '')\n",
      "\n",
      "            try:\n",
      "                print \"%d -- Saving %s ...\" % (num+1, url),\n",
      "                f = os.path.join(BASE_PATH, '%s.jpg') % title\n",
      "                Image.open(StringIO(image_data)).save(f, 'JPEG')\n",
      "                num += 1\n",
      "                print \"done.\"\n",
      "            except IOError, e:\n",
      "                print \"saving FAILED.\"\n",
      "                continue\n",
      "\n",
      "        start += 4 # 4 images per page\n",
      "\n",
      "        # Be nice to Google\n",
      "        time.sleep(1.5)\n",
      "\n",
      "    print \"Completed with %d images downloaded.\" % num"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (c) 2014 Reid Johnson\n",
      "#\n",
      "# Functions to work with images.\n",
      "\n",
      "import Image\n",
      "import os\n",
      "import re\n",
      "\n",
      "import matplotlib.pyplot as pl\n",
      "\n",
      "VERBOSE = False\n",
      "\n",
      "def fetch_paintings(painters_dir, painters_subdirs=None):\n",
      "    \"\"\"Loads paintings from within a specified directory.\n",
      "\n",
      "    Args:\n",
      "      painters_dir (str): The base directory from which to load (.jpg) images from \n",
      "        artist-specific subdirectories.\n",
      "      painters_subdirs (list): A list of specific subdirectories in painters_dir \n",
      "        from which to load the images; subdirectories not included will be skipped.\n",
      "        Defaults to None.\n",
      "\n",
      "    Returns:\n",
      "      images: An array of image objects loaded from the specified directory\n",
      "\n",
      "    \"\"\"\n",
      "    image_shape = (250, 250) # the image dimensions (width and height)\n",
      "\n",
      "    painters = {}\n",
      "\n",
      "    for painter_dir in os.listdir(painters_dir):\n",
      "        if painters_subdirs:\n",
      "            if painter_dir not in painters_subdirs:\n",
      "                continue\n",
      "\n",
      "        painter = re.match( r'(.*) Paintings', painter_dir, re.M|re.I).group(1)\n",
      "\n",
      "        paintings = []\n",
      "        paintings_dir = os.path.join(painters_dir, painter_dir)\n",
      "\n",
      "        for file in os.listdir(paintings_dir):\n",
      "            painting = {}\n",
      "\n",
      "            if VERBOSE:\n",
      "                print file\n",
      "\n",
      "            fp = open(os.path.join(paintings_dir, file), \"rb\")\n",
      "            image = Image.open(fp) # open from file object\n",
      "            image.load() # make sure PIL has read the data\n",
      "            fp.close()\n",
      "\n",
      "            image = image.resize(image_shape)\n",
      "\n",
      "            painting['image'] = image\n",
      "            painting['features'] = []\n",
      "            painting['class'] = painter\n",
      "            paintings.append(painting)\n",
      "\n",
      "        painters[painter] = paintings\n",
      "\n",
      "    return painters\n",
      "\n",
      "# Image pixel values\n",
      "def gen_pixel_fd(painters):\n",
      "    for painter in painters:\n",
      "        for painting in painters[painter]:\n",
      "            fd = np.array(painting['image'], dtype=np.float64) / 255\n",
      "\n",
      "            fd = np.array(fd).flatten()\n",
      "            \n",
      "            painting['features'].extend(fd)\n",
      "\n",
      "# Histogram of RGB color values\n",
      "def gen_hist_fd(painters):\n",
      "    for painter in painters:\n",
      "        for painting in painters[painter]:\n",
      "            fd = painting['image'].histogram()\n",
      "            \n",
      "            fd = np.array(fd).flatten()\n",
      "\n",
      "            painting['features'].extend(fd)\n",
      "\n",
      "# Histogram of Oriented Gradient (HOG) feature descriptor\n",
      "def gen_hog_fd(painters):\n",
      "    hog_grayscale = True # HOG implementation only supports grayscale images\n",
      "    hog_pca = False # apply PCA to each HOG feature descriptor.\n",
      "\n",
      "    for painter in painters:\n",
      "        for painting in painters[painter]:\n",
      "            if hog_grayscale:\n",
      "                painting_gray = np.array(painting['image'], dtype=np.float64) / 255\n",
      "\n",
      "                # Convert image to grayscale\n",
      "                painting_gray = rgb2gray(painting_gray)    \n",
      "                #painting_gray = color.rgb2gray(painting_gray)\n",
      "\n",
      "            try:\n",
      "                import skimage.feature\n",
      "                fd, hog_painting = skimage.feature.hog(painting_gray, orientations=8, pixels_per_cell=(6, 6), \n",
      "                                       cells_per_block=(3, 3), visualise=True)\n",
      "\n",
      "                if VERBOSE:\n",
      "                    plt.figure(figsize=(8, 4))\n",
      "                    plt.subplot(121).set_axis_off()\n",
      "                    plt.imshow(painting['image'], cmap=plt.cm.gray)\n",
      "                    plt.title('Input image')\n",
      "    \n",
      "                    # Rescale histogram for better display\n",
      "                    hog_painting_rescaled = exposure.rescale_intensity(hog_painting, in_range=(0, 0.02))\n",
      "    \n",
      "                    plt.subplot(122).set_axis_off()\n",
      "                    plt.imshow(hog_painting_rescaled, cmap=plt.cm.gray)\n",
      "                    plt.title('Histogram of Oriented Gradients')\n",
      "                    plt.show()\n",
      "            except ImportError, e:\n",
      "                fd = hog(painting_gray, orientations=8, pixels_per_cell=(6, 6), \n",
      "                         cells_per_block=(3, 3), visualise=False)\n",
      "\n",
      "            if hog_pca:\n",
      "                n_components = 10 # the number of components to generate\n",
      "\n",
      "                # Compute PCA on the dataset\n",
      "                estimator = decomposition.RandomizedPCA(n_components=n_components, whiten=True)\n",
      "                fd = estimator.fit_transform(fd)\n",
      "\n",
      "            fd = np.array(fd).flatten()\n",
      "\n",
      "            painting['features'].extend(fd)\n",
      "\n",
      "def plot_image_space(images, X, title=\"Projection of the Images into 2 Dimensions\"):\n",
      "    \"\"\"Generates and shows a plot of images in a feature space.\n",
      "\n",
      "    A figure with one plot is generated. The plot displays the location of each image in \n",
      "    relation to the image's feature values in the input feature space (X).\n",
      "\n",
      "    Args:\n",
      "      images (Image): An image.\n",
      "      X (array): A feature vector.\n",
      "\n",
      "    \"\"\"\n",
      "    # min-max normalization    \n",
      "    x_min, x_max = np.min(X, axis=0), np.max(X, axis=0)\n",
      "    X = (X - x_min) / (x_max - x_min)\n",
      "\n",
      "    # Create a figure\n",
      "    pl.figure(figsize=(16, 5))\n",
      "    ax = pl.subplot(111)\n",
      "    #ax.axis('off')\n",
      "\n",
      "    # Generate picture thumbnails in the plot\n",
      "    if hasattr(matplotlib.offsetbox, 'AnnotationBbox'):\n",
      "        # only print thumbnails with matplotlib > 1.0\n",
      "        for i in range(len(images)):\n",
      "            imagebox = matplotlib.offsetbox.OffsetImage(images[i], zoom=.20)\n",
      "            ab = matplotlib.offsetbox.AnnotationBbox(imagebox, X[i][0:2])                                  \n",
      "            ax.add_artist(ab)\n",
      "\n",
      "    # Add figure labels and ticks\n",
      "    pl.title(title, fontsize=16)\n",
      "    pl.xticks([]), pl.yticks([])\n",
      "\n",
      "    # Add figure bounds\n",
      "    pl.ylim((np.min(X, axis=0)[1])-0.25,(np.max(X, axis=0)[1])+0.25)\n",
      "    pl.xlim((np.min(X, axis=0)[0])-0.1,(np.max(X, axis=0)[0])+0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
